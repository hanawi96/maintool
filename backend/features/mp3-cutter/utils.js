// features/mp3-cutter/utils.js

import ffmpeg from 'fluent-ffmpeg';
import ffmpegPath from 'ffmpeg-static';
import ffprobePath from 'ffprobe-static';
import { promisify } from 'util';
import path from 'path';
import fs from 'fs/promises';
import { MP3_CONFIG, MIME_TYPES } from './constants.js';

// Configure FFmpeg paths
if (ffmpegPath) ffmpeg.setFfmpegPath(ffmpegPath);
if (ffprobePath) ffmpeg.setFfprobePath(ffprobePath.path);

const ffprobe = promisify(ffmpeg.ffprobe);

export class MP3Utils {
  
  /**
   * Get audio file information using FFprobe
   */
  static async getAudioInfo(filePath) {
    try {
      const metadata = await ffprobe(filePath);
      const audioStream = metadata.streams.find(stream => stream.codec_type === 'audio');
      
      if (!audioStream) {
        throw new Error('No audio stream found in file');
      }

      return {
        duration: parseFloat(metadata.format.duration) || 0,
        size: parseInt(metadata.format.size) || 0,
        bitrate: parseInt(metadata.format.bit_rate) || 0,
        format: metadata.format.format_name || 'unknown',
        codec: audioStream.codec_name || 'unknown',
        sampleRate: parseInt(audioStream.sample_rate) || 0,
        channels: audioStream.channels || 0,
        channelLayout: audioStream.channel_layout || 'unknown'
      };
    } catch (error) {
      throw new Error(`Failed to get audio info: ${error.message}`);
    }
  }

  /**
   * Cut audio file with optional fade effects
   */
  static async cutAudio(inputPath, outputPath, options = {}) {
    const {
      startTime = 0,
      endTime,
      fadeIn = 0,
      fadeOut = 0,
      format = 'mp3',
      quality = 'medium',
      playbackRate = 1,
      isInverted = false, // ðŸ†• **INVERT MODE**: Add invert mode parameter
      sessionId = null // ðŸ†• **SESSION ID**: Äá»ƒ identify WebSocket room
    } = options;

    console.log('ðŸŽ¬ [cutAudio] Starting cut operation with options:', {
      startTime,
      endTime,
      fadeIn,
      fadeOut,
      format,
      quality,
      playbackRate,
      isInverted, // ðŸ†• **INVERT MODE**: Log invert mode
      sessionId, // ðŸ†• **LOG SESSION ID**
      speedChangeRequested: playbackRate !== 1,
      cutMode: isInverted ? 'INVERT (cut outside + concatenate)' : 'NORMAL (cut inside)' // ðŸ†• **CUT MODE**
    });

    // ðŸ†• **INVERT MODE LOGIC**: Handle concatenation for invert mode
    if (isInverted && endTime && startTime > 0) {
      console.log('ðŸ”„ [cutAudio] INVERT MODE: Processing concatenation logic');
      return this.cutAudioInvertMode(inputPath, outputPath, options);
    }

    return new Promise((resolve, reject) => {
      try {
        let command = ffmpeg(inputPath);

        // Set input seek (start time)
        if (startTime > 0) {
          command = command.seekInput(startTime);
        }

        // Set duration (if end time specified)
        if (endTime && endTime > startTime) {
          const duration = endTime - startTime;
          command = command.duration(duration);
        }

        // Build audio filters
        const filters = [];
        
        // ðŸ†• **SPEED/TEMPO FILTER**: Thay Ä‘á»•i tá»‘c Ä‘á»™ phÃ¡t vá»›i atempo
        if (playbackRate && playbackRate !== 1) {
          console.log(`âš¡ [cutAudio] Applying speed change: ${playbackRate}x`);
          console.log(`ðŸ”§ [cutAudio] Speed filter logic: playbackRate=${playbackRate}, type=${typeof playbackRate}`);
          
          // ðŸŽ¯ **ATEMPO CHAINING**: FFmpeg atempo chá»‰ há»— trá»£ 0.5-2.0, cáº§n chain cho giÃ¡ trá»‹ cá»±c
          let currentRate = playbackRate;
          const originalRate = playbackRate;
          
          if (currentRate >= 0.5 && currentRate <= 2.0) {
            // ðŸŽ¯ **SINGLE ATEMPO**: Tá»‘c Ä‘á»™ trong khoáº£ng há»— trá»£
            const atempoFilter = `atempo=${currentRate.toFixed(3)}`;
            filters.push(atempoFilter);
            console.log(`ðŸŽ¯ [cutAudio] SINGLE atempo filter: ${atempoFilter}`);
          } else if (currentRate > 2.0) {
            // ðŸŽ¯ **CHAIN FOR FAST**: Tá»‘c Ä‘á»™ > 2x cáº§n chain nhiá»u atempo
            console.log(`ðŸ”— [cutAudio] CHAINING for fast speed > 2x:`, { originalRate: currentRate });
            while (currentRate > 2.0) {
              filters.push(`atempo=2`);
              currentRate /= 2;
              console.log(`ðŸ”— [cutAudio] Added atempo=2, remaining rate: ${currentRate}`);
            }
            if (currentRate > 1.01) { // TrÃ¡nh rounding error
              const finalFilter = `atempo=${currentRate.toFixed(3)}`;
              filters.push(finalFilter);
              console.log(`ðŸ”— [cutAudio] Final atempo filter: ${finalFilter}`);
            }
          } else if (currentRate < 0.5) {
            // ðŸŽ¯ **CHAIN FOR SLOW**: Tá»‘c Ä‘á»™ < 0.5x cáº§n chain nhiá»u atempo  
            console.log(`ðŸ”— [cutAudio] CHAINING for slow speed < 0.5x:`, { originalRate: currentRate });
            while (currentRate < 0.5) {
              filters.push(`atempo=0.5`);
              currentRate *= 2;
              console.log(`ðŸ”— [cutAudio] Added atempo=0.5, remaining rate: ${currentRate}`);
            }
            if (currentRate < 0.99) { // TrÃ¡nh rounding error
              const finalFilter = `atempo=${currentRate.toFixed(3)}`;
              filters.push(finalFilter);
              console.log(`ðŸ”— [cutAudio] Final atempo filter: ${finalFilter}`);
            }
          }
          
          console.log(`âœ… [cutAudio] Speed filters completed for ${originalRate}x:`, filters.filter(f => f.startsWith('atempo')));
        } else {
          console.log(`ðŸš« [cutAudio] No speed change applied (playbackRate=${playbackRate})`);
        }
        
        // Add fade in effect
        if (fadeIn > 0) {
          const fadeInFilter = `afade=t=in:st=0:d=${fadeIn}`;
          filters.push(fadeInFilter);
          console.log(`ðŸŽµ [cutAudio] Added fade in filter: ${fadeInFilter}`);
        }
        
        // Add fade out effect
        if (fadeOut > 0) {
          const segmentDuration = endTime ? (endTime - startTime) : null;
          if (segmentDuration) {
            const fadeOutStart = Math.max(0, segmentDuration - fadeOut);
            const fadeOutFilter = `afade=t=out:st=${fadeOutStart}:d=${fadeOut}`;
            filters.push(fadeOutFilter);
            console.log(`ðŸŽµ [cutAudio] Added fade out filter: ${fadeOutFilter}`);
          }
        }

        // Apply filters if any
        if (filters.length > 0) {
          console.log(`ðŸŽ›ï¸ [cutAudio] Applying ${filters.length} filters:`, filters.join(', '));
          command = command.audioFilters(filters);
        } else {
          console.log(`ðŸš« [cutAudio] No filters to apply`);
        }

        // ðŸ”§ **FORMAT PROCESSING DEBUG**: Log format processing details
        console.log('ðŸŽµ [cutAudio] FORMAT PROCESSING START:', {
          format,
          quality,
          outputPath,
          outputExtension: path.extname(outputPath),
          isM4R: format === 'm4r',
          isM4A: format === 'm4a'
        });

        // Set output quality based on format and quality preset
        try {
          console.log(`ðŸ”§ [cutAudio] Calling setOutputQuality with format: ${format}, quality: ${quality}`);
          command = this.setOutputQuality(command, format, quality);
          console.log(`âœ… [cutAudio] setOutputQuality completed successfully for ${format}`);
        } catch (qualityError) {
          console.error('âŒ [cutAudio] setOutputQuality failed:', {
            format,
            quality,
            error: qualityError.message,
            stack: qualityError.stack
          });
          throw qualityError;
        }

        // ðŸ”Œ **WEBSOCKET PROGRESS EMITTER**: Function Ä‘á»ƒ emit progress
        const emitProgress = (progressData) => {
          if (sessionId && global.io) {
            const roomName = `progress-${sessionId}`;
            console.log(`ðŸ“Š [cutAudio] Emitting progress to room ${roomName}:`, progressData);
            global.io.to(roomName).emit('cut-progress', {
              sessionId,
              ...progressData,
              timestamp: new Date().toISOString()
            });
          }
        };

        // ðŸ“Š **INITIAL PROGRESS**: Emit starting progress
        emitProgress({
          stage: 'initializing',
          percent: 0,
          message: 'Initializing FFmpeg process...'
        });

        command
          .output(outputPath)
          .on('start', (commandLine) => {
            console.log('ðŸš€ [cutAudio] FFmpeg command starting:', commandLine);
            console.log('ðŸ” [cutAudio] Command analysis:', {
              hasAtempo: commandLine.includes('atempo'),
              atempoCount: (commandLine.match(/atempo/g) || []).length,
              fullCommand: commandLine
            });

            // ðŸ“Š **START PROGRESS**: Emit start progress
            emitProgress({
              stage: 'processing',
              percent: 5,
              message: 'FFmpeg processing started...'
            });
          })
          .on('progress', (progress) => {
            // ðŸ“Š **REAL-TIME PROGRESS**: Emit actual FFmpeg progress
            const percent = Math.round(progress.percent || 0);
            const progressData = {
              stage: 'processing', 
              percent: Math.min(95, Math.max(5, percent)), // Clamp between 5-95%
              currentTime: progress.timemark,
              targetSize: progress.targetSize,
              message: `Processing audio... ${percent}%`
            };

            console.log(`ðŸ“Š [cutAudio] FFmpeg progress: ${percent}% - ${progress.timemark}`);
            emitProgress(progressData);

            // ðŸ”„ **LEGACY CALLBACK**: Keep existing callback for backward compatibility
            if (options.onProgress) {
              options.onProgress({
                percent: Math.round(progress.percent || 0),
                currentTime: progress.timemark,
                targetSize: progress.targetSize
              });
            }
          })
          .on('error', (error) => {
            console.error('âŒ [cutAudio] FFmpeg error:', error);
            console.error('âŒ [cutAudio] FFmpeg error context:', {
              inputPath,
              outputPath,
              playbackRate,
              filters,
              errorMessage: error.message
            });

            // ðŸ“Š **ERROR PROGRESS**: Emit error progress
            emitProgress({
              stage: 'error',
              percent: 0,
              message: `Processing failed: ${error.message}`,
              error: error.message
            });

            reject(new Error(`Audio cutting failed: ${error.message}`));
          })
          .on('end', () => {
            console.log('âœ… [cutAudio] FFmpeg processing completed successfully');
            console.log('ðŸŽ‰ [cutAudio] Final result summary:', {
              inputPath,
              outputPath,
              playbackRateApplied: playbackRate,
              filtersApplied: filters,
              speedSuccess: playbackRate !== 1 ? `${playbackRate}x speed applied` : 'normal speed'
            });

            // ðŸ“Š **COMPLETION PROGRESS**: Emit completion progress
            emitProgress({
              stage: 'completed',
              percent: 100,
              message: 'Audio processing completed successfully!',
              success: true
            });
            
            resolve({
              success: true,
              outputPath,
              inputPath,
              settings: {
                startTime,
                endTime,
                duration: endTime - startTime,
                fadeIn,
                fadeOut,
                playbackRate,
                format,
                quality,
                filtersApplied: filters // ðŸ”§ **DEBUG**: Include applied filters in result
              }
            });
          })
          .run();

      } catch (error) {
        console.error('âŒ [cutAudio] Setup failed:', error);
        
        // ðŸ“Š **SETUP ERROR PROGRESS**: Emit setup error
        if (sessionId && global.io) {
          const roomName = `progress-${sessionId}`;
          global.io.to(roomName).emit('cut-progress', {
            sessionId,
            stage: 'error',
            percent: 0,
            message: `Setup failed: ${error.message}`,
            error: error.message,
            timestamp: new Date().toISOString()
          });
        }

        reject(new Error(`Failed to setup audio cutting: ${error.message}`));
      }
    });
  }

  /**
   * ðŸ†• **CHANGE AUDIO SPEED**: Chá»‰ thay Ä‘á»•i tá»‘c Ä‘á»™ khÃ´ng cáº¯t Ä‘oáº¡n
   */
  static async changeAudioSpeed(inputPath, outputPath, options = {}) {
    const {
      playbackRate = 1,
      format = 'mp3',
      quality = 'medium'
    } = options;

    console.log(`âš¡ [changeAudioSpeed] Changing speed to ${playbackRate}x:`, {
      input: inputPath,
      output: outputPath,
      playbackRate
    });

    return new Promise((resolve, reject) => {
      try {
        let command = ffmpeg(inputPath);
        const filters = [];
        
        // ðŸŽ¯ **SPEED ONLY**: Chá»‰ xá»­ lÃ½ tá»‘c Ä‘á»™
        if (playbackRate && playbackRate !== 1) {
          let currentRate = playbackRate;
          
          if (currentRate >= 0.5 && currentRate <= 2.0) {
            filters.push(`atempo=${currentRate.toFixed(3)}`);
          } else if (currentRate > 2.0) {
            while (currentRate > 2.0) {
              filters.push(`atempo=2`);
              currentRate /= 2;
            }
            if (currentRate > 1.01) {
              filters.push(`atempo=${currentRate.toFixed(3)}`);
            }
          } else if (currentRate < 0.5) {
            while (currentRate < 0.5) {
              filters.push(`atempo=0.5`);
              currentRate *= 2;
            }
            if (currentRate < 0.99) {
              filters.push(`atempo=${currentRate.toFixed(3)}`);
            }
          }
        }

        if (filters.length > 0) {
          console.log(`ðŸŽ›ï¸ [changeAudioSpeed] Applying tempo filters:`, filters.join(', '));
          command = command.audioFilters(filters);
        }

        command = this.setOutputQuality(command, format, quality);

        command
          .output(outputPath)
          .on('start', (commandLine) => {
            console.log('âš¡ [changeAudioSpeed] FFmpeg command:', commandLine);
          })
          .on('progress', (progress) => {
            console.log(`âš¡ [changeAudioSpeed] Progress: ${Math.round(progress.percent || 0)}%`);
          })
          .on('error', (error) => {
            console.error('âŒ [changeAudioSpeed] FFmpeg error:', error);
            reject(new Error(`Speed change failed: ${error.message}`));
          })
          .on('end', () => {
            console.log('âœ… [changeAudioSpeed] Speed change completed successfully');
            resolve({
              success: true,
              outputPath,
              inputPath,
              settings: {
                playbackRate,
                format,
                quality
              }
            });
          })
          .run();

      } catch (error) {
        console.error('âŒ [changeAudioSpeed] Setup failed:', error);
        reject(new Error(`Failed to setup speed change: ${error.message}`));
      }
    });
  }

  /**
   * Generate waveform data from audio file
   */
  static async generateWaveform(inputPath, samples = MP3_CONFIG.WAVEFORM.DEFAULT_SAMPLES) {
    return new Promise((resolve, reject) => {
      const waveformData = [];
      let dataCount = 0;
      
      ffmpeg(inputPath)
        .audioFilters([
          `aresample=${MP3_CONFIG.WAVEFORM.SAMPLE_RATE}`,
          'aformat=sample_fmts=s16:channel_layouts=mono'
        ])
        .format('wav')
        .on('error', (error) => {
          reject(new Error(`Waveform generation failed: ${error.message}`));
        })
        .on('end', () => {
          // Normalize waveform to requested sample count
          const step = Math.floor(waveformData.length / samples);
          const normalizedData = [];
          
          for (let i = 0; i < samples && i * step < waveformData.length; i++) {
            normalizedData.push(waveformData[i * step] || 0);
          }
          
          resolve({
            waveform: normalizedData,
            samples: normalizedData.length,
            originalSamples: waveformData.length
          });
        })
        .pipe()
        .on('data', (chunk) => {
          // Process audio data chunks
          for (let i = 0; i < chunk.length && dataCount < samples * 10; i += 2) {
            const sample = chunk.readInt16LE(i);
            const normalizedSample = Math.abs(sample) / 32768; // Normalize to 0-1
            waveformData.push(normalizedSample);
            dataCount++;
          }
        });
    });
  }

  /**
   * Convert audio format
   */
  static async convertFormat(inputPath, outputPath, targetFormat, quality = 'medium') {
    return new Promise((resolve, reject) => {
      let command = ffmpeg(inputPath);
      
      // Set output quality
      command = this.setOutputQuality(command, targetFormat, quality);

      command
        .output(outputPath)
        .on('error', (error) => {
          reject(new Error(`Format conversion failed: ${error.message}`));
        })
        .on('end', () => {
          resolve({
            success: true,
            inputPath,
            outputPath,
            format: targetFormat,
            quality
          });
        })
        .run();
    });
  }

  /**
   * Set output quality based on format and quality preset
   */
  static setOutputQuality(command, format, quality) {
    console.log(`ðŸŽ›ï¸ [setOutputQuality] Setting quality for format: ${format}, quality: ${quality}`);
    
    const qualitySettings = MP3_CONFIG.QUALITY_PRESETS[quality];
    
    if (!qualitySettings || !qualitySettings[format]) {
      console.error(`âŒ [setOutputQuality] Unsupported format/quality combination:`, {
        format,
        quality,
        availableQualities: Object.keys(MP3_CONFIG.QUALITY_PRESETS),
        availableFormats: qualitySettings ? Object.keys(qualitySettings) : 'N/A'
      });
      throw new Error(`Unsupported format/quality combination: ${format}/${quality}`);
    }

    const settings = qualitySettings[format];
    console.log(`ðŸ”§ [setOutputQuality] Using settings for ${format}:`, settings);
    
    // Set audio codec
    command = command.audioCodec(settings.codec);
    
    // Set bitrate if specified
    if (settings.bitrate) {
      command = command.audioBitrate(settings.bitrate);
    }

    // ðŸš¨ **M4R SPECIAL HANDLING**: M4R needs special container format
    if (format === 'm4r') {
      console.log('ðŸŽµ [setOutputQuality] M4R SPECIAL HANDLING: Setting MP4 container format');
      // ðŸŽ¯ **FORCE MP4 CONTAINER**: M4R is basically AAC in MP4 container with .m4r extension
      command = command.format('mp4');
      
      // ðŸ”§ **M4R SPECIFIC OPTIONS**: Additional options for M4R compatibility
      command = command.outputOptions([
        '-f', 'mp4',           // Force MP4 container
        '-movflags', '+faststart' // Optimize for playback
      ]);
      
      console.log('âœ… [setOutputQuality] M4R format configured with MP4 container');
    } else if (format === 'm4a') {
      console.log('ðŸŽµ [setOutputQuality] M4A: Setting MP4 container format');
      // ðŸŽ¯ **M4A CONTAINER**: M4A also uses MP4 container
      command = command.format('mp4');
      command = command.outputOptions([
        '-f', 'mp4',
        '-movflags', '+faststart'
      ]);
      console.log('âœ… [setOutputQuality] M4A format configured with MP4 container');
    } else if (format === 'flac') {
      console.log('ðŸŽµ [setOutputQuality] FLAC: Setting FLAC container format');
      command = command.format('flac');
    } else if (format === 'ogg') {
      console.log('ðŸŽµ [setOutputQuality] OGG: Setting OGG container format');
      command = command.format('ogg');
    }
    // ðŸš« **NO EXPLICIT FORMAT**: MP3, WAV, AAC use default container detection

    console.log(`âœ… [setOutputQuality] Quality configuration completed for ${format}`);
    return command;
  }

  /**
   * Generate unique output filename
   */
  static generateOutputFilename(originalFilename, suffix = '', format = 'mp3') {
    const timestamp = Date.now();
    const random = Math.random().toString(36).substring(2, 8);
    const baseName = path.parse(originalFilename).name;
    
    return `${baseName}_${suffix}_${timestamp}_${random}.${format}`;
  }

  /**
   * Ensure directory exists
   */
  static async ensureDirectory(dirPath) {
    try {
      await fs.access(dirPath);
    } catch {
      await fs.mkdir(dirPath, { recursive: true });
    }
  }

  /**
   * Get file extension from path
   */
  static getFileExtension(filePath) {
    return path.extname(filePath).toLowerCase().slice(1);
  }

  /**
   * Get MIME type for audio format
   */
  static getMimeType(format) {
    return MIME_TYPES[format] || 'application/octet-stream';
  }

  /**
   * Validate audio file format
   */
  static isValidAudioFormat(filename) {
    const ext = this.getFileExtension(filename);
    return MP3_CONFIG.SUPPORTED_INPUT_FORMATS.includes(ext);
  }

  /**
   * Validate output format
   */
  static isValidOutputFormat(format) {
    return MP3_CONFIG.SUPPORTED_OUTPUT_FORMATS.includes(format);
  }

  /**
   * Calculate file duration from start/end times
   */
  static calculateDuration(startTime, endTime) {
    return endTime > startTime ? endTime - startTime : 0;
  }

  /**
   * Format time in seconds to MM:SS format
   */
  static formatTime(seconds) {
    const mins = Math.floor(seconds / 60);
    const secs = Math.floor(seconds % 60);
    return `${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`;
  }

  /**
   * Test FFmpeg availability
   */
  static async testFFmpeg() {
    return new Promise((resolve, reject) => {
      ffmpeg()
        .version((err, version) => {
          if (err) {
            reject(new Error(`FFmpeg not available: ${err.message}`));
          } else {
            resolve(version);
          }
        });
    });
  }

  /**
   * ðŸ†• **CUT AUDIO INVERT MODE**: Cut and concatenate segments outside selected region
   */
  static async cutAudioInvertMode(inputPath, outputPath, options = {}) {
    const {
      startTime = 0,
      endTime,
      fadeIn = 0,
      fadeOut = 0,
      format = 'mp3',
      quality = 'medium',
      playbackRate = 1,
      sessionId = null
    } = options;

    console.log('ðŸ”„ [cutAudioInvertMode] Starting invert mode concatenation:', {
      startTime,
      endTime,
      fadeIn,
      fadeOut,
      format,
      quality,
      playbackRate,
      sessionId
    });

    // ðŸ”Œ **WEBSOCKET PROGRESS EMITTER**: Function Ä‘á»ƒ emit progress
    const emitProgress = (progressData) => {
      if (sessionId && global.io) {
        const roomName = `progress-${sessionId}`;
        console.log(`ðŸ“Š [cutAudioInvertMode] Emitting progress to room ${roomName}:`, progressData);
        global.io.to(roomName).emit('cut-progress', {
          sessionId,
          ...progressData,
          timestamp: new Date().toISOString()
        });
      }
    };

    return new Promise((resolve, reject) => {
      try {
        // ðŸ“Š **INITIAL PROGRESS**: Emit starting progress
        emitProgress({
          stage: 'initializing',
          percent: 0,
          message: 'Initializing invert mode concatenation...'
        });

        // ðŸ”— **FFmpeg CONCATENATION**: Use FFmpeg filter_complex to concatenate segments
        let command = ffmpeg(inputPath);

        // Build complex filter for concatenation
        const filters = [];
        
        // ðŸ†• **SEGMENT EXTRACTION**: Extract two segments and concatenate
        // Segment 1: 0 â†’ startTime
        // Segment 2: endTime â†’ end of file
        
        const segment1Filter = `[0:a]atrim=start=0:end=${startTime}[seg1]`;
        const segment2Filter = `[0:a]atrim=start=${endTime}[seg2]`;
        
        filters.push(segment1Filter);
        filters.push(segment2Filter);

        // ðŸ†• **SPEED/TEMPO FILTERS**: Apply speed change to each segment if needed
        if (playbackRate && playbackRate !== 1) {
          console.log(`âš¡ [cutAudioInvertMode] Applying speed change: ${playbackRate}x to both segments`);
          
          // Build atempo chain for segments
          const atempoChain = this.buildAtempoChain(playbackRate);
          
          // Apply to segment 1
          const seg1SpeedFilter = `[seg1]${atempoChain}[seg1_speed]`;
          filters.push(seg1SpeedFilter);
          
          // Apply to segment 2 
          const seg2SpeedFilter = `[seg2]${atempoChain}[seg2_speed]`;
          filters.push(seg2SpeedFilter);
          
          // Concatenate speed-adjusted segments
          const concatFilter = `[seg1_speed][seg2_speed]concat=n=2:v=0:a=1[out]`;
          filters.push(concatFilter);
        } else {
          // No speed change, just concatenate
          const concatFilter = `[seg1][seg2]concat=n=2:v=0:a=1[out]`;
          filters.push(concatFilter);
        }

        // ðŸ†• **FADE EFFECTS**: Apply fade to final output if needed
        if (fadeIn > 0 || fadeOut > 0) {
          const fadeFilters = [];
          if (fadeIn > 0) {
            fadeFilters.push(`afade=t=in:st=0:d=${fadeIn}`);
          }
          if (fadeOut > 0) {
            fadeFilters.push(`afade=t=out:st=0:d=${fadeOut}`); // Will be calculated properly by FFmpeg
          }
          
          if (fadeFilters.length > 0) {
            const lastOutputLabel = playbackRate !== 1 ? '[out]' : '[out]';
            const fadeFilter = `${lastOutputLabel}${fadeFilters.join(',')}[final]`;
            filters.push(fadeFilter);
          }
        }

        // Apply complex filter
        const complexFilter = filters.join(';');
        console.log('ðŸ”— [cutAudioInvertMode] Complex filter:', complexFilter);
        
        command = command.complexFilter(complexFilter);
        
        // Map output
        const outputLabel = (fadeIn > 0 || fadeOut > 0) ? '[final]' : '[out]';
        command = command.outputOptions([`-map`, outputLabel]);

        // Set output quality
        command = this.setOutputQuality(command, format, quality);

        command
          .output(outputPath)
          .on('start', (commandLine) => {
            console.log('ðŸš€ [cutAudioInvertMode] FFmpeg command starting:', commandLine);
            emitProgress({
              stage: 'processing',
              percent: 10,
              message: 'Processing invert mode concatenation...'
            });
          })
          .on('progress', (progress) => {
            const percent = Math.round(progress.percent || 0);
            const progressData = {
              stage: 'processing',
              percent: Math.min(90, Math.max(10, percent)),
              message: `Concatenating segments... ${percent}%`
            };
            emitProgress(progressData);
          })
          .on('end', () => {
            console.log('âœ… [cutAudioInvertMode] Invert mode concatenation completed successfully');
            emitProgress({
              stage: 'completed',
              percent: 100,
              message: 'Invert mode concatenation completed!'
            });
            
            resolve({
              success: true,
              settings: {
                startTime,
                endTime,
                fadeIn,
                fadeOut,
                playbackRate,
                format,
                quality,
                isInverted: true,
                duration: startTime + (endTime > 0 ? 0 : endTime) // Approximate duration
              }
            });
          })
          .on('error', (error) => {
            console.error('âŒ [cutAudioInvertMode] FFmpeg error:', error);
            emitProgress({
              stage: 'error',
              percent: 0,
              message: `Error: ${error.message}`
            });
            reject(error);
          })
          .run();

      } catch (error) {
        console.error('âŒ [cutAudioInvertMode] Setup error:', error);
        emitProgress({
          stage: 'error',
          percent: 0,
          message: `Setup error: ${error.message}`
        });
        reject(error);
      }
    });
  }

  /**
   * ðŸ†• **BUILD ATEMPO CHAIN**: Build atempo filter chain for speed changes
   */
  static buildAtempoChain(playbackRate) {
    const atempoFilters = [];
    let currentRate = playbackRate;
    
    if (currentRate >= 0.5 && currentRate <= 2.0) {
      atempoFilters.push(`atempo=${currentRate.toFixed(3)}`);
    } else if (currentRate > 2.0) {
      while (currentRate > 2.0) {
        atempoFilters.push(`atempo=2`);
        currentRate /= 2;
      }
      if (currentRate > 1.01) {
        atempoFilters.push(`atempo=${currentRate.toFixed(3)}`);
      }
    } else if (currentRate < 0.5) {
      while (currentRate < 0.5) {
        atempoFilters.push(`atempo=0.5`);
        currentRate *= 2;
      }
      if (currentRate < 0.99) {
        atempoFilters.push(`atempo=${currentRate.toFixed(3)}`);
      }
    }
    
    return atempoFilters.join(',');
  }
}